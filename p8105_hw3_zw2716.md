Homework 3
================
Iris (Ziyi) Wang
2020-10-10

### Due date

Due: October 10 at 10:00pm.

### Points

| Problem         | Points    |
| :-------------- | :-------- |
| Problem 0       | 20        |
| Problem 1       | –         |
| Problem 2       | 40        |
| Problem 3       | 40        |
| Optional survey | No points |

### Problem 0

This “problem” focuses on structure of your submission, especially the
use git and GitHub for reproducibility, R Projects to organize your
work, R Markdown to write reproducible reports, relative paths to load
data from local files, and reasonable naming structures for your files.

### Problem 1

``` r
data("instacart")
```

This dataset contains 1384617 rows and 15 columns.

Observations are the level of items in orders by user. There are user /
order variables – user ID, order ID, order day, and order hour. There
are also item variables – name, aisle, department, and some numeric
codes.

How many aisles, and which are most items from?

``` r
instacart %>% 
    count(aisle) %>% 
    arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # … with 124 more rows

Let’s make a plot

``` r
instacart %>% 
    count(aisle) %>% 
    filter(n > 10000) %>% 
    mutate(
        aisle = factor(aisle),
        aisle = fct_reorder(aisle, n)
    ) %>% 
    ggplot(aes(x = aisle, y = n)) + 
    geom_point() + 
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

<img src="p8105_hw3_zw2716_files/figure-gfm/unnamed-chunk-3-1.png" width="90%" />

Let’s make a table\!\!

``` r
instacart %>% 
    filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
    group_by(aisle) %>% 
    count(product_name) %>% 
    mutate(rank = min_rank(desc(n))) %>% 
    filter(rank < 4) %>% 
    arrange(aisle, rank) %>% 
    knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

Apples vs ice cream..

``` r
instacart %>% 
    filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
    group_by(product_name, order_dow) %>% 
    summarize(mean_hour = mean(order_hour_of_day)) %>% 
    pivot_wider(
        names_from = order_dow,
        values_from = mean_hour
    )
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

    ## # A tibble: 2 x 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

### Problem 2

#### Load, tidy, and otherwise wrangle the accelerometer data.

``` r
path_to_P2_data = "./data/accel_data.csv"
accelerometer = read_csv(path_to_P2_data) %>% 
    janitor::clean_names() %>% 
    pivot_longer(
        cols = starts_with("activity_"),
        names_to = 'activity_number',
        values_to = "activity_minute",
        names_prefix = "activity_") %>% 
    mutate(
        activity_minute = as.numeric(activity_minute),
        activity_number = as.numeric(activity_number),
        day = factor(day),
        # add weekday_vs_weekend variable
        week_end_vs_day = ifelse(day_id == c(3,4), "weekend", "weekday")
    )
skimr::skim_without_charts(accelerometer)
```

|                                                  |               |
| :----------------------------------------------- | :------------ |
| Name                                             | accelerometer |
| Number of rows                                   | 50400         |
| Number of columns                                | 6             |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |               |
| Column type frequency:                           |               |
| character                                        | 1             |
| factor                                           | 1             |
| numeric                                          | 4             |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |               |
| Group variables                                  | None          |

Data summary

**Variable type: character**

| skim\_variable     | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
| :----------------- | ---------: | -------------: | --: | --: | ----: | --------: | ---------: |
| week\_end\_vs\_day |          0 |              1 |   7 |   7 |     0 |         2 |          0 |

**Variable type: factor**

| skim\_variable | n\_missing | complete\_rate | ordered | n\_unique | top\_counts                                |
| :------------- | ---------: | -------------: | :------ | --------: | :----------------------------------------- |
| day            |          0 |              1 | FALSE   |         7 | Fri: 7200, Mon: 7200, Sat: 7200, Sun: 7200 |

**Variable type: numeric**

| skim\_variable   | n\_missing | complete\_rate |   mean |     sd | p0 |    p25 |   p50 |     p75 | p100 |
| :--------------- | ---------: | -------------: | -----: | -----: | -: | -----: | ----: | ------: | ---: |
| week             |          0 |              1 |   3.00 |   1.41 |  1 |   2.00 |   3.0 |    4.00 |    5 |
| day\_id          |          0 |              1 |  18.00 |  10.10 |  1 |   9.00 |  18.0 |   27.00 |   35 |
| activity\_number |          0 |              1 | 720.50 | 415.70 |  1 | 360.75 | 720.5 | 1080.25 | 1440 |
| activity\_minute |          0 |              1 | 267.04 | 443.16 |  1 |   1.00 |  74.0 |  364.00 | 8982 |

After tidy and wrangle the data, the resulting ***accelerometer*** data
contains 50400 rows and 6 columns. The variables in the
***accelerometer*** are: week, day\_id, day, activity\_number,
activity\_minute, week\_end\_vs\_day. Specifically,
**weekday\_vs\_weekend** shows whether the day is a weekday or weekend;
**activity\_minute** and **activity\_number** shows the minute for each
activities.

#### Traditional analyses of accelerometer data

``` r
# aggregate activity_minute to get total_activity var. for each day
accelerometer %>% 
    group_by(week,day) %>% 
    summarize(total_activity = sum(activity_minute)) %>% 
    # create a table showing these totals
    pivot_wider(names_from = day,
                values_from = total_activity) %>% 
    knitr::kable()
```

| week |   Friday |    Monday | Saturday | Sunday | Thursday |  Tuesday | Wednesday |
| ---: | -------: | --------: | -------: | -----: | -------: | -------: | --------: |
|    1 | 480542.6 |  78828.07 |   376254 | 631105 | 355923.6 | 307094.2 |    340115 |
|    2 | 568839.0 | 295431.00 |   607175 | 422018 | 474048.0 | 423245.0 |    440962 |
|    3 | 467420.0 | 685910.00 |   382928 | 467052 | 371230.0 | 381507.0 |    468869 |
|    4 | 154049.0 | 409450.00 |     1440 | 260617 | 340291.0 | 319568.0 |    434460 |
|    5 | 620860.0 | 389080.00 |     1440 | 138421 | 549658.0 | 367824.0 |    445366 |

Apparent trend I noticed is that week 4 and 5’s Saturday both have the
exact same amount of low activity, so I am a little curious whether that
two numbers are resulted from reading error or technical error, or the
person just happen to move less and has the same amount of activity.
Another potential trend is that this person has relatively the same
amount of activity on Wednesdays and Thursdays.

#### single-panel plot: 24-hour activity time courses for each day

``` r
accelerometer %>% 
    ggplot(aes(x = activity_number, 
               y = activity_minute, 
               color = day, group = day_id)) +
    geom_smooth(se = F, method = "loess", geom = "line", alpha = 0.5) +
    labs(title = "24-hour activity time courses for each day",
         x = "Time in a day (in minutes)",
         y = "Activity Count") +
    guides(color = guide_legend(nrow = 1, byrow = T))
```

<img src="p8105_hw3_zw2716_files/figure-gfm/single-panel plot-1.png" width="90%" />
Based on the above graph, I see the person has more activity during the
(middle of the) day, and less/no activity during the early morning and
late night. This makes sense as people generally asleep during the early
morning and late night, and work during the (middle of the) day. In
addition, this person seems to very low (almost 0) activities on one
Saturday and Monday, maybe this is due to the person did not (forgot to)
put on the accelerometer as him/she started the day.

### Problem 3

First,
